{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "import openai\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_python_agent(\n",
    "    llm=OpenAI(temperature=0, max_tokens=1000, openai_api_key=openai.api_key),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all designers names from the main pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use a web scraper to get the href names\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'https://www.vogue.com/fashion-shows'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "links = soup.find_all('a', href=True)\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to filter out the href names for fall-2023-ready-to-wear\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "fall_2023_links = [link['href'] for link in links if 'fall-2023-ready-to-wear' in link['href']]\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: fall_2023_links\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fall_2023_links'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"scrappe all href names of fall-2023-ready-to-wear from the web page https://www.vogue.com/fashion-shows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get('https://www.vogue.com/fashion-shows')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#hrefs = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "links = soup.find_all('a', href=True)\n",
    "\n",
    "fall_2023_links = []\n",
    "for link in links:\n",
    "    if 'fall-2023-ready-to-wear' in link['href']:\n",
    "        fall_2023_links.append(link['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fall_2023_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all text about fashion show and images from designers pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use a web scraper to get the text and images from the website\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to get the text and images from the page\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "text = soup.find_all('p')\n",
      "images = soup.find_all('img')\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now have the text and images from the page\n",
      "Final Answer: The text and images from the page can be accessed using the variables 'text' and 'images'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The text and images from the page can be accessed using the variables 'text' and 'images'.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"scrappe all the text and images from https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "text = soup.find_all('p')\n",
    "images = soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use a web scraper to get the image src links\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project'\n",
      "page = requests.get(url)\n",
      "soup = BeautifulSoup(page.content, 'html.parser')\n",
      "\n",
      "images = soup.find_all('img')\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to get the src links from the images\n",
      "Action: Python REPL\n",
      "Action Input: \n",
      "image_src_links = []\n",
      "for image in images:\n",
      "    image_src_links.append(image['src'])\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The image src links are: [image_src_links]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The image src links are: [image_src_links]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"scrappe all the images src link from https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.vogue.com/fashion-shows/fall-2023-ready-to-wear/y-project'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "images = soup.find_all('img')\n",
    "image_src_links = []\n",
    "for image in images:\n",
    "    image_src_links.append(image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data of a-company\n",
      "Downloading data of a-l-c\n",
      "Downloading data of a-p-c-\n",
      "Downloading data of a-w-a-k-e-\n",
      "Downloading data of acne-studios\n",
      "Downloading data of adam-lippes\n",
      "Downloading data of adeam\n",
      "Downloading data of ag\n",
      "Downloading data of agl\n",
      "Downloading data of ahluwalia-studio\n",
      "Downloading data of akris\n",
      "Downloading data of azzedine-alaia\n",
      "Downloading data of alberta-ferretti\n",
      "Downloading data of alejandra-alonso-rojas\n",
      "Downloading data of alessandra-rich\n",
      "Downloading data of alexander-mcqueen\n",
      "Downloading data of alexander-wang\n",
      "Downloading data of alexandre-vauthier\n",
      "Downloading data of alexis-mabille\n",
      "Downloading data of alice-olivia\n",
      "Downloading data of altuzarra\n",
      "Downloading data of alyx\n",
      "Downloading data of ambush\n",
      "Downloading data of andreadamo\n",
      "Downloading data of andreas-kronthaler-for-vivienne-westwood\n",
      "Downloading data of andrew-gn\n",
      "Downloading data of ann-demeulemeester\n",
      "Downloading data of anna-october\n",
      "Downloading data of anna-sui\n",
      "Downloading data of anonlychild\n",
      "Downloading data of anrealage\n",
      "Downloading data of anteprima\n",
      "Downloading data of antonio-marras\n",
      "Downloading data of armarium\n",
      "Downloading data of arthur-arbesser\n",
      "Downloading data of asai\n",
      "Downloading data of ashish\n",
      "Downloading data of ashlyn\n",
      "Downloading data of aspesi\n",
      "Downloading data of atlein\n",
      "Downloading data of atxv\n",
      "Downloading data of autumn-adeigbo\n",
      "Downloading data of avavav\n",
      "Downloading data of az-factory\n",
      "Downloading data of bach-mai\n",
      "Downloading data of badgley-mischka\n",
      "Downloading data of balenciaga\n",
      "Downloading data of bally\n",
      "Downloading data of balmain\n",
      "Downloading data of barbara-tfank\n",
      "Downloading data of batsheva\n",
      "Downloading data of beatrice-b\n",
      "Downloading data of bevza\n",
      "Downloading data of bibhu-mohapatra\n",
      "Downloading data of bite-studios\n",
      "Downloading data of blumarine\n",
      "Downloading data of bora-aksu\n",
      "Downloading data of bottega-veneta\n",
      "Downloading data of brandon-maxwell\n",
      "Downloading data of bronx-and-banco\n",
      "Downloading data of brunello-cucinelli\n",
      "Downloading data of burberry-prorsum\n",
      "Downloading data of callas-milano\n",
      "Downloading data of calvin-luo\n",
      "Downloading data of carolina-herrera\n",
      "Downloading data of caroline-hu\n",
      "Downloading data of cecilie-bahnsen\n",
      "Downloading data of central-saint-martins\n",
      "Downloading data of cfcl\n",
      "Downloading data of chanel\n",
      "Downloading data of chet-lo\n",
      "Downloading data of chloe\n",
      "Downloading data of chocheng\n",
      "Downloading data of chopova-lowena\n",
      "Downloading data of christian-cowan\n",
      "Downloading data of christian-dior\n",
      "Downloading data of christian-siriano\n",
      "Downloading data of christopher-kane\n",
      "Downloading data of chufy\n",
      "Downloading data of cinq-a-sept\n",
      "Downloading data of coach\n",
      "Downloading data of collina-strada\n",
      "Downloading data of comme-des-garcons\n",
      "Downloading data of commission\n",
      "Downloading data of conner-ives\n",
      "Downloading data of coperni\n",
      "Downloading data of cormio\n",
      "Downloading data of courreges\n",
      "Downloading data of danielle-frankel\n",
      "Downloading data of david-koma\n",
      "Downloading data of del-core\n",
      "Downloading data of derek-lam-10-crosby\n",
      "Downloading data of di-petsa\n",
      "Downloading data of diesel\n",
      "Downloading data of dilara-findikoglu\n",
      "Downloading data of dion-lee\n",
      "Downloading data of dolce-gabbana\n",
      "Downloading data of dries-van-noten\n",
      "Downloading data of dsquared\n",
      "Downloading data of dundas\n",
      "Downloading data of duran-lantink\n",
      "Downloading data of duro-olowu\n",
      "Downloading data of eckhaus-latta\n",
      "Downloading data of edeline-lee\n",
      "Downloading data of edward-crutchley\n",
      "Downloading data of elena-velez\n",
      "Downloading data of elie-saab\n",
      "Downloading data of emilia-wickstead\n",
      "Downloading data of emporio-armani\n",
      "Downloading data of erdem\n",
      "Downloading data of erl\n",
      "Downloading data of ermanno-scervino\n",
      "Downloading data of ester-manas\n",
      "Downloading data of et-ochs\n",
      "Downloading data of etro\n",
      "Downloading data of eudon-choi\n",
      "Downloading data of eytys\n",
      "Downloading data of fashion-east\n",
      "Downloading data of feben\n",
      "Downloading data of fendi\n",
      "Downloading data of salvatore-ferragamo\n",
      "Downloading data of ferrari\n",
      "Downloading data of fforme\n",
      "Downloading data of for-restless-sleepers\n",
      "Downloading data of frederick-anderson\n",
      "Downloading data of gabriela-hearst\n",
      "Downloading data of gauchere\n",
      "Downloading data of gcds\n",
      "Downloading data of genny\n",
      "Downloading data of giambattista-valli\n",
      "Downloading data of giorgio-armani\n",
      "Downloading data of givenchy\n",
      "Downloading data of gmbh\n",
      "Downloading data of greta-constantine\n",
      "Downloading data of gucci\n",
      "Downloading data of harris-reed\n",
      "Downloading data of head-of-state\n",
      "Downloading data of heliot-emil\n",
      "Downloading data of hermes\n",
      "Downloading data of heron-preston\n",
      "Downloading data of hodakova\n",
      "Downloading data of hope-for-flowers\n",
      "Downloading data of house-of-aama\n",
      "Downloading data of hui\n",
      "Downloading data of huishan-zhang\n",
      "Downloading data of in-earnest-by-byron-lars\n",
      "Downloading data of institut-francais-de-la-mode\n",
      "Downloading data of interior\n",
      "Downloading data of iro\n",
      "Downloading data of isabel-marant\n",
      "Downloading data of issey-miyake\n",
      "Downloading data of j6\n",
      "Downloading data of jason-wu\n",
      "Downloading data of jenny-packham\n",
      "Downloading data of jil-sander\n",
      "Downloading data of johanna-ortiz\n",
      "Downloading data of judy-turner\n",
      "Downloading data of junya-watanabe\n",
      "Downloading data of j-w-anderson\n",
      "Downloading data of k-krizia\n",
      "Downloading data of kate-spade-new-york\n",
      "Downloading data of khaite\n",
      "Downloading data of kiko-kostadinov\n",
      "Downloading data of kim-shui\n",
      "Downloading data of kitx\n",
      "Downloading data of koche\n",
      "Downloading data of kolor\n",
      "Downloading data of krizia\n",
      "Downloading data of la-doublej\n",
      "Downloading data of labrum-london\n",
      "Downloading data of lafayette-148\n",
      "Downloading data of lala-berlin\n",
      "Downloading data of lanvin\n",
      "Downloading data of sally-lapointe\n",
      "Downloading data of laquan-smith\n",
      "Downloading data of lauren-manoogian\n",
      "Downloading data of lela-rose\n",
      "Downloading data of libertine\n",
      "Downloading data of loewe\n",
      "Downloading data of longchamp\n",
      "Downloading data of lorena-antoniazzi\n",
      "Downloading data of loro-piana\n",
      "Downloading data of louis-vuitton\n",
      "Downloading data of loveshackfancy\n",
      "Downloading data of luar\n",
      "Downloading data of luisa-beccaria\n",
      "Downloading data of lutz-huelle\n",
      "Downloading data of maisie-wilen\n",
      "Downloading data of maison-martin-margiela\n",
      "Downloading data of maje\n",
      "Downloading data of mame-kurogouchi\n",
      "Downloading data of marco-rambaldi\n",
      "Downloading data of margaret-howell\n",
      "Downloading data of maria-mcmanus\n",
      "Downloading data of marina-moscone\n",
      "Downloading data of marine-serre\n",
      "Downloading data of mark-fast\n",
      "Downloading data of markarian\n",
      "Downloading data of marni\n",
      "Downloading data of marques-almeida\n",
      "Downloading data of maryam-nassir-zadeh\n",
      "Downloading data of matty-bovan\n",
      "Downloading data of max-mara\n",
      "Downloading data of max-mara-atelier\n",
      "Downloading data of melitta-baumeister\n",
      "Downloading data of meryll-rogge\n",
      "Downloading data of michael-kors-collection\n",
      "Downloading data of mira-mikati\n",
      "Downloading data of missoni\n",
      "Downloading data of mithridate\n",
      "Downloading data of miu-miu\n",
      "Downloading data of mm6-maison-martin-margiela\n",
      "Downloading data of molly-goddard\n",
      "Downloading data of moncler-genius\n",
      "Downloading data of monique-lhuillier\n",
      "Downloading data of moschino\n",
      "Downloading data of mossi\n",
      "Downloading data of mowalola\n",
      "Downloading data of msgm\n",
      "Downloading data of n-hoolywood\n",
      "Downloading data of naeem-khan\n",
      "Downloading data of nanushka\n",
      "Downloading data of natasha-zinko\n",
      "Downloading data of nehera\n",
      "Downloading data of nells-nelson\n",
      "Downloading data of nensi-dojaka\n",
      "Downloading data of niccolo-pasqualetti\n",
      "Downloading data of nili-lotan\n",
      "Downloading data of nina-ricci\n",
      "Downloading data of no-21\n",
      "Downloading data of noir-kei-ninomiya\n",
      "Downloading data of nomia\n",
      "Downloading data of norma-kamali\n",
      "Downloading data of off-white\n",
      "Downloading data of ottolinger\n",
      "Downloading data of our-legacy\n",
      "Downloading data of paco-rabanne\n",
      "Downloading data of palm-angels\n",
      "Downloading data of palmerharding\n",
      "Downloading data of palomo-spain\n",
      "Downloading data of paolina-russo\n",
      "Downloading data of nellie-partow\n",
      "Downloading data of patou\n",
      "Downloading data of patrick-mcdowell\n",
      "Downloading data of paul-smith\n",
      "Downloading data of paula-canovas-del-vas\n",
      "Downloading data of petar-petrov\n",
      "Downloading data of ph5\n",
      "Downloading data of philipp-plein\n",
      "Downloading data of philosophy\n",
      "Downloading data of plan-c\n",
      "Downloading data of polo-ralph-lauren\n",
      "Downloading data of prabal-gurung\n",
      "Downloading data of prada\n",
      "Downloading data of priscavera\n",
      "Downloading data of private-policy\n",
      "Downloading data of proenza-schouler\n",
      "Downloading data of pt-torino\n",
      "Downloading data of puppets-and-puppets\n",
      "Downloading data of quira\n",
      "Downloading data of r13\n",
      "Downloading data of rachel-comey\n",
      "Downloading data of rag-bone\n",
      "Downloading data of ralph-lauren\n",
      "Downloading data of raquel-allegra\n",
      "Downloading data of rave-review\n",
      "Downloading data of reem-acra\n",
      "Downloading data of renaissance-renaissance\n",
      "Downloading data of rentrayage\n",
      "Downloading data of rev\n",
      "Downloading data of richard-quinn\n",
      "Downloading data of rick-owens\n",
      "Downloading data of roberto-cavalli\n",
      "Downloading data of rochas\n",
      "Downloading data of rodarte\n",
      "Downloading data of rodebjer\n",
      "Downloading data of roisin-pierce\n",
      "Downloading data of rokh\n",
      "Downloading data of roksanda\n",
      "Downloading data of roland-mouret\n",
      "Downloading data of romance-was-born\n",
      "Downloading data of rosetta-getty\n",
      "Downloading data of rosie-assoulin\n",
      "Downloading data of rta\n",
      "Downloading data of rue-agthonis\n",
      "Downloading data of ss-daley\n",
      "Downloading data of sacai\n",
      "Downloading data of saint-laurent\n",
      "Downloading data of saint-sintra\n",
      "Downloading data of sandy-liang\n",
      "Downloading data of sara-battaglia\n",
      "Downloading data of sc103\n",
      "Downloading data of schiaparelli\n",
      "Downloading data of sea\n",
      "Downloading data of self-portrait\n",
      "Downloading data of shang-xia\n",
      "Downloading data of sharon-wauchob\n",
      "Downloading data of shuting-qiu\n",
      "Downloading data of sid-neigum\n",
      "Downloading data of jonathan-simkhai\n",
      "Downloading data of simone-rocha\n",
      "Downloading data of sinead-odwyer\n",
      "Downloading data of snow-xue-gao\n",
      "Downloading data of sportmax\n",
      "Downloading data of st-john\n",
      "Downloading data of staud\n",
      "Downloading data of stella-jean\n",
      "Downloading data of stella-mccartney\n",
      "Downloading data of sukeina\n",
      "Downloading data of sunnei\n",
      "Downloading data of susan-fang\n",
      "Downloading data of system\n",
      "Downloading data of talia-byre\n",
      "Downloading data of tanner-fletcher\n",
      "Downloading data of tanya-taylor\n",
      "Downloading data of temperley-london\n",
      "Downloading data of elder-statesman\n",
      "Downloading data of row\n",
      "Downloading data of thebe-magugu\n",
      "Downloading data of theory\n",
      "Downloading data of thom-browne\n",
      "Downloading data of tia-adeola\n",
      "Downloading data of tibi\n",
      "Downloading data of tiger-of-sweden\n",
      "Downloading data of tod-s\n",
      "Downloading data of toga\n",
      "Downloading data of tokyo-james\n",
      "Downloading data of tomo-koizumi\n",
      "Downloading data of tory-burch\n",
      "Downloading data of tove\n",
      "Downloading data of trussardi\n",
      "Downloading data of ulla-johnson\n",
      "Downloading data of uma-wang\n",
      "Downloading data of undercover\n",
      "Downloading data of valentino\n",
      "Downloading data of vaquera\n",
      "Downloading data of veronica-beard\n",
      "Downloading data of versace\n",
      "Downloading data of victoria-beckham\n",
      "Downloading data of vivetta\n",
      "Downloading data of vivienne-westwood\n",
      "Downloading data of vtmnts\n",
      "Downloading data of we11done\n",
      "Downloading data of wiederhoeft\n",
      "Downloading data of willie-norris-for-outlier\n",
      "Downloading data of xulybet\n",
      "Downloading data of y-project\n",
      "Downloading data of yeohlee\n",
      "Downloading data of yigal-azrouel\n",
      "Downloading data of yohji-yamamoto\n",
      "Downloading data of yuhan-wang\n",
      "Downloading data of zankov\n",
      "Downloading data of zero-maria-cornejo\n",
      "Downloading data of zimmermann\n",
      "Downloading data of zuhair-murad\n",
      "Downloading data of 16arlington\n",
      "Downloading data of 3-1-phillip-lim\n",
      "Downloading data of 6397\n",
      "Downloading data of versace\n",
      "Downloading data of y-project\n",
      "Downloading data of miu-miu\n",
      "Downloading data of chanel\n",
      "Downloading data of rokh\n",
      "Downloading data of sacai\n",
      "Downloading data of louis-vuitton\n",
      "Downloading data of az-factory\n",
      "Downloading data of stella-mccartney\n",
      "Downloading data of valentino\n",
      "Downloading data of danielle-frankel\n",
      "Downloading data of danielle-frankel\n",
      "Downloading data of kitx\n",
      "Downloading data of kitx\n",
      "Downloading data of ralph-lauren\n",
      "Downloading data of ralph-lauren\n",
      "Downloading data of quira\n",
      "Downloading data of quira\n"
     ]
    }
   ],
   "source": [
    "df_text = pd.DataFrame()\n",
    "df_image = pd.DataFrame()\n",
    "text_n = 0\n",
    "image_n = 0\n",
    "for designer_show in fall_2023_links:\n",
    "    designer_name = designer_show.split(\"/\")[-1]\n",
    "    print(f\"Downloading data of {designer_name}\")\n",
    "    df_text.loc[text_n,\"designer\"] = designer_name\n",
    "    url = f'https://www.vogue.com{designer_show}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    if soup.find('div', class_='body__inner-container'):\n",
    "        texts = soup.find('div', class_='body__inner-container').get_text()\n",
    "        df_text.loc[text_n,\"text_runway\"] = texts\n",
    "        text_n += 1\n",
    "    images = soup.find_all('img')\n",
    "    image_src_links = []\n",
    "    for image in images:\n",
    "        if \"runway\" in image['src'] and \"https\" in image['src']:\n",
    "            image_src_links.append(image['src'])\n",
    "            df_image.loc[image_n,\"designer\"] = designer_name\n",
    "            df_image.loc[image_n,\"image_link\"] = image['src']\n",
    "            image_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designer</th>\n",
       "      <th>text_runway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a-company</td>\n",
       "      <td>“I feel protected by history.” So said A--Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a-l-c</td>\n",
       "      <td>Real clothes won at New York fashion week this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>“The kids are all right” was Jean Touitou’s su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a-w-a-k-e-</td>\n",
       "      <td>Natalia Alaverdian arrived at Paris Fashion We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acne-studios</td>\n",
       "      <td>With crystal strands dripping from twisted tre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       designer                                        text_runway\n",
       "0     a-company  “I feel protected by history.” So said A--Comp...\n",
       "1         a-l-c  Real clothes won at New York fashion week this...\n",
       "2        a-p-c-  “The kids are all right” was Jean Touitou’s su...\n",
       "3    a-w-a-k-e-  Natalia Alaverdian arrived at Paris Fashion We...\n",
       "4  acne-studios  With crystal strands dripping from twisted tre..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designers from vogue runway fashion shows: 2254\n"
     ]
    }
   ],
   "source": [
    "print(f\"Designers from vogue runway fashion shows: {len(df_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designer</th>\n",
       "      <th>image_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>https://assets.vogue.com/photos/6404d2f8068d12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>https://assets.vogue.com/photos/6404d2bbc12f0b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>https://assets.vogue.com/photos/6404d2bc194566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>https://assets.vogue.com/photos/6404da4544574b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a-p-c-</td>\n",
       "      <td>https://assets.vogue.com/photos/6404d2be7b0104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  designer                                         image_link\n",
       "0   a-p-c-  https://assets.vogue.com/photos/6404d2f8068d12...\n",
       "1   a-p-c-  https://assets.vogue.com/photos/6404d2bbc12f0b...\n",
       "2   a-p-c-  https://assets.vogue.com/photos/6404d2bc194566...\n",
       "3   a-p-c-  https://assets.vogue.com/photos/6404da4544574b...\n",
       "4   a-p-c-  https://assets.vogue.com/photos/6404d2be7b0104..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images obtained from vogue runway fashion shows: 2254\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images obtained from vogue runway fashion shows: {len(df_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.to_csv(\"image_vougue_runway.csv\", index=False)\n",
    "df_text.to_csv(\"text_vougue_runway.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"text_vougue_runway.csv\")\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=\" \")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "with open(\"vogue_shows.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(vectorstore):\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai.api_key, model_name=\"gpt-3.5-turbo\")\n",
    "    qa_chain = ChatVectorDBChain.from_llm(\n",
    "        llm,\n",
    "        vectorstore,\n",
    "        top_k_docs_for_context=3\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpastur/miniconda3/envs/web3MBA/lib/python3.11/site-packages/langchain/llms/openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/lpastur/miniconda3/envs/web3MBA/lib/python3.11/site-packages/langchain/llms/openai.py:623: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/lpastur/miniconda3/envs/web3MBA/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py:191: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa_chain = get_chain(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    chat_history = []\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bottega Veneta collection is described as a knock-out and a rare feat that simultaneously ups the fashion ante while also delivering real-life relatability. The collection is diverse and adheres to no developing trends because together they were all different. The designer, Matthieu Blazy, started with the street and the idea of the strange encounter—people that you meet in the street and they really amaze you. The collection includes breakthrough leather tank tops and leather jeans, layered dresses with sweet flower embroideries, deconstructed 1950s screen star dresses, and an exceptional LBD with a swooping neckline and a front slit not quite high enough to reveal the top of over-the-knee intrecciato boots. The materials used are light, unconstrained fabrics, and the silhouettes sometimes went to extremes.\n"
     ]
    }
   ],
   "source": [
    "question = \"How is the Bottega Veneta collection?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A breakthrough leather tank top, leather jeans, and a fringed coat woven in one piece.\n"
     ]
    }
   ],
   "source": [
    "question = \"Describe 3 items from the Bottega Veneta collection?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bottega Veneta collection featured 81 looks that were all different and did not adhere to any developing trends. The collection started with a sheer dressing gown and house shoes, and included breakthrough leather tank tops and leather jeans. There were layered dresses with sweet flower embroideries, deconstructed 1950s screen star dresses, and an exceptional LBD with a swooping neckline and a front slit not quite high enough to reveal the top of over-the-knee intrecciato boots. The collection also featured cleanly tailored double-layer coats and jackets for women and men, as well as bulbous jelly pumps. Materials-wise, the designer used light, unconstrained fabrics, and shaved leather to make it more weightless. The collection also included a fringed coat that was woven in one piece, and rolled waistband skirts that were meant to conjure the fishtail bottom half of mermaids. The designer's inclination this season was to start with the street, and “the idea of the strange encounter—people that you meet in the street and they really amaze you. It’s a place where everyone belongs,” like a parade, or Carnevale, “where there is absolutely no hierarchy.” The Boccioni statue and the Roman bronzes loaned from museums for the show were “part of the parade,” and the idea was to reconnect Italy through its history.\n"
     ]
    }
   ],
   "source": [
    "question = \"Describe all items from the Bottega Veneta collection?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sheer dressing gown and house shoes: This luxurious dressing gown is perfect for lounging at home, with its sheer fabric and comfortable fit. The matching house shoes are made from knitted leather, adding a touch of sophistication to your at-home look.\n",
      "\n",
      "2. Leather tank top and jeans: Make a statement in this edgy leather tank top and jeans set. The tank top features a breakthrough design, while the jeans are made from weightless shaved leather for a comfortable fit.\n",
      "\n",
      "3. LBD with intrecciato boots: This little black dress is anything but basic, with a swooping neckline and front slit that shows off your over-the-knee intrecciato boots. The perfect outfit for a night out on the town.\n"
     ]
    }
   ],
   "source": [
    "question = \"Describe three items from the Bottega Veneta collection as an online product description for a ecommerce\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web3MBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10a19d2d4d405e4bd0c14e9810352d77d7b2e44a31220dee5e45e2120b45d0ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
